# Music-Dataset-Analysis-using-PySpark
###Overview
This project demonstrates how to perform distributed data processing using PySpark on Google Colab. It covers various tasks including mounting Google Drive, importing large datasets into PySpark dataframes, applying queries to extract useful information, joining dataframes, and visualizing query results using matplotlib.

###Getting Started
To run the code provided in this project, follow these steps:

Set up Google Colab: Ensure you have a Google account and access to Google Colab. Google Colab provides a free Jupyter notebook environment that allows you to run Python code in the cloud.

Mount Google Drive: To access files stored in your Google Drive, you need to mount your Google Drive into the Google Colab environment. The code snippet for mounting Google Drive is provided in the notebook.

Import Datasets: Import the datasets into PySpark dataframes. The first file is a sample dataset (96 Mb), and the second file is a smaller dataset (3 MB). The provided code demonstrates how to import these datasets into PySpark dataframes.

Query Data: Apply queries to extract useful information from the datasets. PySpark provides powerful SQL-like functionalities for data manipulation and analysis. You can use PySpark SQL or DataFrame API to perform queries.

Join Dataframes: If necessary, join the two dataframes to combine information from different datasets. Joins allow you to merge data based on common keys or columns.

Visualize Query Results: Use matplotlib, a popular Python visualization library, to visualize the results of your queries. Visualizations help in understanding the data and identifying patterns or trends.

Files Included
Music_dataset_analysis.ipynb: Jupyter notebook containing the code for distributed data processing on Google Colab.
Listenings_Sample_dataset.csv: Example of a sample dataset (96 Mb) used for demonstration purposes.
Dependencies
Python 3.x
PySpark
Matplotlib
Usage
Open the Music_dataset_analysis.ipynb notebook in Google Colab.
Follow the instructions provided in the notebook to execute each code cell.
Modify the code as needed for your specific datasets and analysis requirements.
Credits
This project was created by Sachin Patel. You can reach out to linkedin.com/in/sachinrkp for any inquiries or feedback.

Happy data processing!
